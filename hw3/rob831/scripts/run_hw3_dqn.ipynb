{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gUl_qfOR8JV6"},"source":["##Setup\n","\n","You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."]},{"cell_type":"code","metadata":{"id":"iizPcHAp8LnA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665272071832,"user_tz":240,"elapsed":15571,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}},"outputId":"2230fd2f-ee7e-46ad-a097-6a9891cd401d"},"source":["#@title mount your Google Drive\n","#@markdown Your work will be stored in a folder called `hw_16831` by default to prevent Colab instance timeouts from deleting your edits.\n","\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"nAb10wnb8N0m","executionInfo":{"status":"ok","timestamp":1665272071946,"user_tz":240,"elapsed":116,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}}},"source":["#@title set up mount symlink\n","\n","DRIVE_PATH = '/content/gdrive/My\\ Drive/hw_16831'\n","DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n","if not os.path.exists(DRIVE_PYTHON_PATH):\n","  %mkdir $DRIVE_PATH\n","\n","## the space in `My Drive` causes some issues,\n","## make a symlink to avoid this\n","SYM_PATH = '/content/hw_16831'\n","if not os.path.exists(SYM_PATH):\n","  !ln -s $DRIVE_PATH $SYM_PATH"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtS9-WsD8QVr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665272112060,"user_tz":240,"elapsed":40116,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}},"outputId":"7521c225-1af5-46a8-ae25-1e7a9c2cee55"},"source":["#@title apt install requirements\n","\n","#@markdown Run each section with Shift+Enter\n","\n","#@markdown Double-click on section headers to show code.\n","\n","!apt update \n","!apt install -y --no-install-recommends \\\n","        build-essential \\\n","        curl \\\n","        git \\\n","        gnupg2 \\\n","        make \\\n","        cmake \\\n","        ffmpeg \\\n","        swig \\\n","        libz-dev \\\n","        unzip \\\n","        zlib1g-dev \\\n","        libffi-dev \\\n","        libglfw3 \\\n","        libglfw3-dev \\\n","        libxrandr2 \\\n","        libxinerama-dev \\\n","        libxi6 \\\n","        libxcursor-dev \\\n","        libgl1-mesa-dev \\\n","        libgl1-mesa-glx \\\n","        libglew-dev \\\n","        libosmesa6-dev \\\n","        lsb-release \\\n","        ack-grep \\\n","        patchelf \\\n","        wget \\\n","        xpra \\\n","        xserver-xorg-dev \\\n","        xvfb \\\n","        python-opengl \\\n","        software-properties-common \\\n","        ffmpeg > /dev/null 2>&1\n","\n","\n","!pip install opencv-python==4.4.0.42"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\u001b[33m\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Waiting for headers] [\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\u001b[0m\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\u001b[33m\r0% [1 InRelease gpgv 242 kB] [3 InRelease 8,192 B/88.7 kB 9%] [Waiting for head\u001b[0m\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\u001b[33m\r0% [1 InRelease gpgv 242 kB] [3 InRelease 15.6 kB/88.7 kB 18%] [Waiting for hea\u001b[0m\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [950 kB]\n","Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,324 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,424 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,992 kB]\n","Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,546 kB]\n","Fetched 11.5 MB in 3s (3,966 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","12 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opencv-python==4.4.0.42\n","  Downloading opencv_python-4.4.0.42-cp37-cp37m-manylinux2014_x86_64.whl (49.4 MB)\n","\u001b[K     |████████████████████████████████| 49.4 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.4.0.42) (1.21.6)\n","Installing collected packages: opencv-python\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.6.0.66\n","    Uninstalling opencv-python-4.6.0.66:\n","      Successfully uninstalled opencv-python-4.6.0.66\n","Successfully installed opencv-python-4.4.0.42\n"]}]},{"cell_type":"code","source":["#@title download mujoco\n","\n","MJC_PATH = '{}/mujoco'.format(SYM_PATH)\n","if not os.path.exists(MJC_PATH):\n","  %mkdir $MJC_PATH\n","%cd $MJC_PATH\n","if not os.path.exists(os.path.join(MJC_PATH, 'mujoco200')):\n","  !wget -q https://www.roboti.us/download/mujoco200_linux.zip\n","  !unzip -q mujoco200_linux.zip\n","  %mv mujoco200_linux mujoco200\n","  %rm mujoco200_linux.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJben3Vdowd0","executionInfo":{"status":"ok","timestamp":1665272112258,"user_tz":240,"elapsed":108,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}},"outputId":"600d6b2e-55d7-4bf7-c70d-1db3193a024e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/hw_16831/mujoco\n"]}]},{"cell_type":"code","source":["#@title update mujoco paths\n","\n","import os\n","\n","os.environ['LD_LIBRARY_PATH'] += ':{}/mujoco200/bin'.format(MJC_PATH)\n","os.environ['MUJOCO_PY_MUJOCO_PATH'] = '{}/mujoco200'.format(MJC_PATH)\n","os.environ['MUJOCO_PY_MJKEY_PATH'] = '{}/mjkey.txt'.format(MJC_PATH)\n","os.environ['LD_LIBRARY_PATH'] += ':/usr/lib/nvidia'\n","\n","## installation on colab does not find *.so files\n","## in LD_LIBRARY_PATH, copy over manually instead\n","!cp $MJC_PATH/mujoco200/bin/*.so /usr/lib/x86_64-linux-gnu/"],"metadata":{"id":"wx6DIQs3pHOe","executionInfo":{"status":"ok","timestamp":1665272114207,"user_tz":240,"elapsed":1840,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-XcwBiBN8-Fg","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1665272159208,"user_tz":240,"elapsed":45007,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}},"outputId":"805622ed-79c7-4972-d9d5-e22a3269caa0"},"source":["#@title clone homework repo\n","#@markdown Note that this is the same codebase from homework 1,\n","#@markdown so you may need to move your old `hw_16831`\n","#@markdown folder in order to clone the repo again.\n","\n","#@markdown **Don't delete your old work though!**\n","#@markdown You will need it for this assignment.\n","\n","%cd /content\n","# !git clone https://github.com/berkeleydeeprlcourse/homework_fall2021.git\n","\n","%cd /content/gdrive/MyDrive/hw3_16831_solutions\n","# %cd /hw_16831/hw3_16831_solutions\n","%pip install -r requirements_colab.txt -f https://download.pytorch.org/whl/torch_stable.html\n","%pip install -e ."],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/gdrive/MyDrive/hw3_16831_solutions\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting numpy==1.21.3\n","  Downloading numpy-1.21.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 3.8 MB/s \n","\u001b[?25hCollecting mujoco==2.2.1\n","  Downloading mujoco-2.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[K     |████████████████████████████████| 3.7 MB 45.3 MB/s \n","\u001b[?25hCollecting free-mujoco-py==2.1.6\n","  Downloading free_mujoco_py-2.1.6-py3-none-any.whl (14.1 MB)\n","\u001b[K     |████████████████████████████████| 14.1 MB 45.6 MB/s \n","\u001b[?25hCollecting gym==0.17.2\n","  Downloading gym-0.17.2.tar.gz (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 50.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard==2.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements_colab.txt (line 6)) (2.8.0)\n","Collecting tensorboardX==2.5.1\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 81.4 MB/s \n","\u001b[?25hCollecting matplotlib==3.1.3\n","  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n","\u001b[K     |████████████████████████████████| 13.1 MB 66.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements_colab.txt (line 9)) (1.12.1+cu113)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements_colab.txt (line 10)) (7.9.0)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from -r requirements_colab.txt (line 11)) (0.2.3.5)\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: opencv-python==4.4.0.42 in /usr/local/lib/python3.7/dist-packages (from -r requirements_colab.txt (line 13)) (4.4.0.42)\n","Collecting ipdb==0.13.3\n","  Downloading ipdb-0.13.3.tar.gz (14 kB)\n","Collecting box2d-py\n","  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 71.5 MB/s \n","\u001b[?25hCollecting glfw\n","  Downloading glfw-2.5.5-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 75.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.7/dist-packages (from mujoco==2.2.1->-r requirements_colab.txt (line 2)) (3.1.6)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mujoco==2.2.1->-r requirements_colab.txt (line 2)) (1.2.0)\n","  Downloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203 kB)\n","\u001b[K     |████████████████████████████████| 203 kB 76.7 MB/s \n","\u001b[?25hRequirement already satisfied: Cython<0.30.0,>=0.29.24 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py==2.1.6->-r requirements_colab.txt (line 3)) (0.29.32)\n","Collecting fasteners==0.15\n","  Downloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: imageio<3.0.0,>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py==2.1.6->-r requirements_colab.txt (line 3)) (2.9.0)\n","Requirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py==2.1.6->-r requirements_colab.txt (line 3)) (1.15.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->-r requirements_colab.txt (line 4)) (1.7.3)\n","Collecting pyglet<=1.5.0,>=1.4.0\n","  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 54.2 MB/s \n","\u001b[?25hCollecting cloudpickle<1.4.0,>=1.2.0\n","  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (3.4.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (1.49.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (3.17.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (2.23.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (0.37.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (0.6.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements_colab.txt (line 8)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements_colab.txt (line 8)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements_colab.txt (line 8)) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements_colab.txt (line 8)) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->-r requirements_colab.txt (line 9)) (4.1.1)\n","Collecting monotonic>=0.1\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners==0.15->free-mujoco-py==2.1.6->-r requirements_colab.txt (line 3)) (1.15.0)\n","Requirement already satisfied: atari_py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->-r requirements_colab.txt (line 4)) (0.2.9)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->-r requirements_colab.txt (line 4)) (7.1.2)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements_colab.txt (line 10)) (2.0.10)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements_colab.txt (line 10)) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements_colab.txt (line 10)) (2.6.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements_colab.txt (line 10)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements_colab.txt (line 10)) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements_colab.txt (line 10)) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements_colab.txt (line 10)) (0.2.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 52.0 MB/s \n","\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py==2.1.6->-r requirements_colab.txt (line 3)) (2.21)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements_colab.txt (line 10)) (0.8.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (3.8.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements_colab.txt (line 10)) (0.2.5)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (0.4.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.2->-r requirements_colab.txt (line 4)) (0.16.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0->-r requirements_colab.txt (line 6)) (3.2.1)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->-r requirements_colab.txt (line 11)) (4.64.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements_colab.txt (line 10)) (0.7.0)\n","Building wheels for collected packages: gym, ipdb\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650890 sha256=54356b049976020ad57e68b7903ce8e2a5a3324996ba38d57b979ad43b14af89\n","  Stored in directory: /root/.cache/pip/wheels/18/e1/58/89a2aa24e6c2cc800204fc02010612afdf200926c4d6bfe315\n","  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipdb: filename=ipdb-0.13.3-py3-none-any.whl size=10875 sha256=05593b0967d9e17fca5c678f5115d4e3c5ede04e91bda7e99ae653c39aa9883e\n","  Stored in directory: /root/.cache/pip/wheels/b1/2b/e0/4932698c94c886d9d476e90916b43af63d5e708e146eb8b273\n","Successfully built gym ipdb\n","Installing collected packages: numpy, pyglet, monotonic, jedi, cloudpickle, gym, glfw, fasteners, tensorboardX, pyvirtualdisplay, mujoco, matplotlib, ipdb, free-mujoco-py, box2d-py\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.5.0\n","    Uninstalling cloudpickle-1.5.0:\n","      Successfully uninstalled cloudpickle-1.5.0\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","distributed 2022.2.0 requires cloudpickle>=1.5.0, but you have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n","Successfully installed box2d-py-2.3.8 cloudpickle-1.3.0 fasteners-0.15 free-mujoco-py-2.1.6 glfw-1.12.0 gym-0.17.2 ipdb-0.13.3 jedi-0.18.1 matplotlib-3.1.3 monotonic-1.6 mujoco-2.2.1 numpy-1.21.3 pyglet-1.5.0 pyvirtualdisplay-3.0 tensorboardX-2.5.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits","numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/gdrive/My%20Drive/hw3_16831_solutions\n","Installing collected packages: rob831\n","  Running setup.py develop for rob831\n","Successfully installed rob831-0.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"edu3tXLiQNuI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665272208472,"user_tz":240,"elapsed":49267,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}},"outputId":"e8142821-083b-4a3c-c0c6-229018d539e6"},"source":["#@title set up the Ms. Pacman environment\n","\n","#import urllib.request\n","#urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')\n","#!pip install unrar\n","#!unrar x Roms.rar\n","#!mkdir rars\n","#!mv HC\\ ROMS/*   rars\n","#!mv ROMS/*  rars\n","!python -m atari_py.import_roms rars"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["copying riverraid.bin from rars/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n","copying video_pinball.bin from rars/Pinball (AKA Video Pinball) (Zellers).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n","copying road_runner.bin from patched version of rars/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n","copying surround.bin from rars/Surround (32 in 1) (Bit Corporation) (R320).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n","copying alien.bin from rars/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n","copying adventure.bin from rars/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n","copying air_raid.bin from rars/Air Raid (Men-A-Vision) (PAL) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n","copying amidar.bin from rars/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n","copying assault.bin from rars/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n","copying asterix.bin from rars/Asterix (AKA Taz) (1984) (Atari, Jerome Domurat, Steve Woita) (CX2696).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n","copying asteroids.bin from rars/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n","copying atlantis.bin from rars/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n","copying battle_zone.bin from rars/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n","copying bank_heist.bin from rars/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n","copying beam_rider.bin from rars/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n","copying berzerk.bin from rars/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n","copying breakout.bin from rars/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n","copying bowling.bin from rars/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n","copying boxing.bin from rars/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n","copying carnival.bin from rars/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n","copying centipede.bin from rars/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n","copying pacman.bin from rars/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n","copying koolaid.bin from rars/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n","copying star_gunner.bin from rars/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n","copying trondead.bin from rars/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n","copying robotank.bin from rars/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n","copying space_invaders.bin from rars/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n","copying hero.bin from rars/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n","copying montezuma_revenge.bin from rars/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n","copying crazy_climber.bin from rars/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n","copying defender.bin from rars/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n","copying double_dunk.bin from rars/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n","copying donkey_kong.bin from rars/Donkey Kong (1987) (Atari) (CX26143).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n","copying enduro.bin from rars/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n","copying frostbite.bin from rars/Frostbite (Iceman) (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n","copying frogger.bin from rars/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n","copying fishing_derby.bin from rars/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n","copying gopher.bin from rars/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n","copying gravitar.bin from rars/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n","copying galaxian.bin from rars/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n","copying journey_escape.bin from rars/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n","copying kangaroo.bin from rars/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n","copying krull.bin from rars/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n","copying name_this_game.bin from rars/Name This Game (Guardians of Treasure, Octopussy) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n","copying qbert.bin from rars/Q-bert (1987) (Atari) (CX26150).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n","copying phoenix.bin from rars/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n","copying pooyan.bin from rars/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n","copying private_eye.bin from rars/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n","copying seaquest.bin from rars/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n","copying solaris.bin from rars/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n","copying time_pilot.bin from rars/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n","copying tutankham.bin from rars/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n","copying zaxxon.bin from rars/Zaxxon (1983) (Coleco) (2454) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n","copying pong.bin from rars/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n","copying venture.bin from rars/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n","copying wizard_of_wor.bin from rars/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n","copying yars_revenge.bin from rars/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n","copying jamesbond.bin from rars/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Dan Kurczewski, Louis Marbel, Kathy Von) (PB5110) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n","copying keystone_kapers.bin from rars/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n","copying king_kong.bin from rars/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n","copying laser_gates.bin from rars/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n","copying sir_lancelot.bin from rars/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n","copying mr_do.bin from rars/Mr. Do! (1983) (CBS Electronics - Individeo, Ed English) (4L4478) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n","copying lost_luggage.bin from rars/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n","copying elevator_action.bin from rars/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n","copying ms_pacman.bin from rars/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n","copying up_n_down.bin from rars/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n","copying kung_fu_master.bin from rars/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n","copying pitfall.bin from rars/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n","copying chopper_command.bin from rars/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n","copying ice_hockey.bin from rars/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n","copying freeway.bin from rars/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n","copying kaboom.bin from rars/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, CAG-010, AG-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n","copying skiing.bin from rars/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n","copying tennis.bin from rars/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n","copying demon_attack.bin from rars/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n"]}]},{"cell_type":"code","metadata":{"id":"g5xIOIpW8_jC","executionInfo":{"status":"ok","timestamp":1665272209915,"user_tz":240,"elapsed":1464,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}}},"source":["#@title set up virtual display\n","\n","from pyvirtualdisplay import Display\n","\n","display = Display(visible=0, size=(1400, 900))\n","display.start()\n","\n","# For later\n","from rob831.infrastructure.colab_utils import (\n","    wrap_env,\n","    show_video\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rsWAWaK9BVp","colab":{"base_uri":"https://localhost:8080/","height":771},"executionInfo":{"status":"ok","timestamp":1665272268144,"user_tz":240,"elapsed":58232,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}},"outputId":"cb59618f-db88-4b8b-cfb0-b9cb0a36f1f3"},"source":["#@title test virtual display\n","\n","#@markdown If you see a video of a four-legged ant fumbling about, setup is complete!\n","\n","import gym\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","env = wrap_env(gym.make(\"Ant-v2\"))\n","\n","observation = env.reset()\n","for i in range(10):\n","    env.render(mode='rgb_array')\n","    obs, rew, term, _ = env.step(env.action_space.sample() ) \n","    if term:\n","      break;\n","            \n","env.close()\n","print('Loading video...')\n","show_video()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Compiling /usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.pyx because it changed.\n","[1/1] Cythonizing /usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.pyx\n","running build_ext\n","building 'mujoco_py.cymj' extension\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/gl\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/mujoco_py -I/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.c -o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.o -fopenmp -w\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/mujoco_py -I/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /usr/local/lib/python3.7/dist-packages/mujoco_py/gl/osmesashim.c -o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/gl/osmesashim.o -fopenmp -w\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7\n","creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/gl/osmesashim.o -L/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -Wl,--enable-new-dtags,-R/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -lmujoco210 -lglewosmesa -lOSMesa -lGL -o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py/cymj.cpython-37m-x86_64-linux-gnu.so -fopenmp\n","Loading video...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"QizpiHDh9Fwk"},"source":["## Editing Code\n","\n","To edit code, click the folder icon on the left menu. Navigate to the corresponding file (`hw_16831/...`). Double click a file to open an editor. There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window). We sync your edits to Google Drive so that you won't lose your work in the event of an instance timeout, but you will need to re-mount your Google Drive and re-install packages with every new instance."]},{"cell_type":"markdown","metadata":{"id":"Nii6qk2C9Ipk"},"source":["## Run DQN and Double DQN"]},{"cell_type":"code","metadata":{"id":"4t7FUeEG9Dkf","executionInfo":{"status":"ok","timestamp":1665272272943,"user_tz":240,"elapsed":4819,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}}},"source":["#@title imports\n","import os\n","import time\n","\n","from rob831.infrastructure.rl_trainer import RL_Trainer\n","from rob831.agents.dqn_agent import DQNAgent\n","from rob831.infrastructure.dqn_utils import get_env_kwargs"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"2fXlzARJ9i-t","executionInfo":{"status":"ok","timestamp":1665272272944,"user_tz":240,"elapsed":13,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}}},"source":["#@title runtime arguments\n","\n","class Args:\n","\n","  def __getitem__(self, key):\n","    return getattr(self, key)\n","\n","  def __setitem__(self, key, val):\n","    setattr(self, key, val)\n","\n","  def __contains__(self, key):\n","    return hasattr(self, key)\n","\n","  env_name = 'MsPacman-v0' #@param ['MsPacman-v0', 'LunarLander-v3', 'PongNoFrameSkip-v4']\n","  exp_name = 'q3_dqn' #@param\n","\n","  ## PDF will tell you how to set ep_len\n","  ## and discount for each environment\n","  ep_len = 200 #@param {type: \"integer\"}\n","\n","  #@markdown batches and steps\n","  batch_size = 32 #@param {type: \"integer\"}\n","  eval_batch_size = 1000 #@param {type: \"integer\"}\n","\n","  num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n","\n","  num_critic_updates_per_agent_update = 1 #@param {type: \"integer\"}\n","  \n","  #@markdown Q-learning parameters\n","  double_q = True #@param {type: \"boolean\"}\n","\n","  #@markdown system\n","  save_params = False #@param {type: \"boolean\"}\n","  no_gpu = False #@param {type: \"boolean\"}\n","  which_gpu = 0 #@param {type: \"integer\"}\n","  seed = 1 #@param {type: \"integer\"}\n","\n","  #@markdown logging\n","  ## default is to not log video so\n","  ## that logs are small enough to be\n","  ## uploaded to gradscope\n","  video_log_freq =  -1 #@param {type: \"integer\"}\n","  scalar_log_freq =  10000#@param {type: \"integer\"}\n","\n","\n","args = Args()\n","\n","## ensure compatibility with hw1 code\n","args['train_batch_size'] = args['batch_size']\n","\n","if args['video_log_freq'] > 0:\n","  import warnings\n","  warnings.warn(\n","      '''\\nLogging videos will make eventfiles too'''\n","      '''\\nlarge for the autograder. Set video_log_freq = -1'''\n","      '''\\nfor the runs you intend to submit.''')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0cJlp6s-ogO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665272273348,"user_tz":240,"elapsed":415,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}},"outputId":"30af243d-6670-4428-c72b-f4569899420d"},"source":["#@title create directories for logging\n","\n","data_path = '''/content/hw_16831/hw_16831/data'''\n","\n","if not (os.path.exists(data_path)):\n","    os.makedirs(data_path)\n","\n","logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n","logdir = os.path.join(data_path, logdir)\n","args['logdir'] = logdir\n","if not(os.path.exists(logdir)):\n","    os.makedirs(logdir)\n","\n","print(\"LOGGING TO: \", logdir)\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["LOGGING TO:  /content/hw_16831/hw_16831/data/q3_dqn_MsPacman-v0_08-10-2022_23-37-52\n"]}]},{"cell_type":"code","metadata":{"id":"I525KFRN-42s","executionInfo":{"status":"ok","timestamp":1665272273349,"user_tz":240,"elapsed":5,"user":{"displayName":"Sam Triest","userId":"10231915509310259522"}}},"source":["#@title Define Q-function trainer\n","\n","class Q_Trainer(object):\n","\n","    def __init__(self, params):\n","        self.params = params\n","\n","        train_args = {\n","            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n","            'num_critic_updates_per_agent_update': params['num_critic_updates_per_agent_update'],\n","            'train_batch_size': params['batch_size'],\n","            'double_q': params['double_q'],\n","        }\n","\n","        env_args = get_env_kwargs(params['env_name'])\n","\n","        for k, v in env_args.items():\n","          params[k] = v\n","\n","        self.params['agent_class'] = DQNAgent\n","        self.params['agent_params'] = params\n","        self.params['train_batch_size'] = params['batch_size']\n","        self.params['env_wrappers'] = env_args['env_wrappers']\n","\n","        self.rl_trainer = RL_Trainer(self.params)\n","\n","    def run_training_loop(self):\n","        self.rl_trainer.run_training_loop(\n","            self.params['num_timesteps'],\n","            collect_policy = self.rl_trainer.agent.actor,\n","            eval_policy = self.rl_trainer.agent.actor,\n","            )"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"wF4LSRGn-_Cv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"738eafdb-8820-491f-94f4-3a7cbca196fc"},"source":["#@title run training\n","\n","trainer = Q_Trainer(args)\n","trainer.run_training_loop()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","********** Iteration 118000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 119000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 120000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 120001\n","mean reward (100 episodes) 450.800000\n","best mean reward 473.400000\n","running time 889.066563\n","Train_EnvstepsSoFar : 120001\n","Train_AverageReturn : 450.8\n","Train_BestReturn : 473.4\n","TimeSinceStart : 889.0665633678436\n","Training Loss : 0.099204882979393\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 121000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 122000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 123000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 124000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 125000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 126000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 127000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 128000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 129000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 130000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 130001\n","mean reward (100 episodes) 490.300000\n","best mean reward 490.300000\n","running time 972.597872\n","Train_EnvstepsSoFar : 130001\n","Train_AverageReturn : 490.3\n","Train_BestReturn : 490.3\n","TimeSinceStart : 972.5978715419769\n","Training Loss : 0.044879235327243805\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 131000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 132000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 133000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 134000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 135000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 136000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 137000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 138000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 139000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 140000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 140001\n","mean reward (100 episodes) 524.000000\n","best mean reward 524.000000\n","running time 1055.866699\n","Train_EnvstepsSoFar : 140001\n","Train_AverageReturn : 524.0\n","Train_BestReturn : 524.0\n","TimeSinceStart : 1055.86669921875\n","Training Loss : 0.07612138241529465\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 141000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 142000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 143000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 144000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 145000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 146000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 147000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 148000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 149000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 150000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 150001\n","mean reward (100 episodes) 511.700000\n","best mean reward 524.000000\n","running time 1139.772434\n","Train_EnvstepsSoFar : 150001\n","Train_AverageReturn : 511.7\n","Train_BestReturn : 524.0\n","TimeSinceStart : 1139.7724344730377\n","Training Loss : 0.0330156646668911\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 151000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 152000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 153000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 154000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 155000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 156000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 157000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 158000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 159000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 160000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 160001\n","mean reward (100 episodes) 523.900000\n","best mean reward 524.000000\n","running time 1223.748888\n","Train_EnvstepsSoFar : 160001\n","Train_AverageReturn : 523.9\n","Train_BestReturn : 524.0\n","TimeSinceStart : 1223.74888753891\n","Training Loss : 0.09522481262683868\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 161000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 162000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 163000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 164000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 165000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 166000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 167000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 168000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 169000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 170000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 170001\n","mean reward (100 episodes) 551.900000\n","best mean reward 551.900000\n","running time 1307.366294\n","Train_EnvstepsSoFar : 170001\n","Train_AverageReturn : 551.9\n","Train_BestReturn : 551.9\n","TimeSinceStart : 1307.366293668747\n","Training Loss : 0.08156171441078186\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 171000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 172000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 173000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 174000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 175000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 176000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 177000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 178000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 179000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 180000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 180001\n","mean reward (100 episodes) 542.600000\n","best mean reward 551.900000\n","running time 1391.206339\n","Train_EnvstepsSoFar : 180001\n","Train_AverageReturn : 542.6\n","Train_BestReturn : 551.9\n","TimeSinceStart : 1391.2063393592834\n","Training Loss : 0.09675469994544983\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 181000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 182000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 183000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 184000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 185000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 186000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 187000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 188000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 189000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 190000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 190001\n","mean reward (100 episodes) 514.300000\n","best mean reward 551.900000\n","running time 1475.619270\n","Train_EnvstepsSoFar : 190001\n","Train_AverageReturn : 514.3\n","Train_BestReturn : 551.9\n","TimeSinceStart : 1475.6192698478699\n","Training Loss : 0.04345355182886124\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 191000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 192000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 193000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 194000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 195000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 196000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 197000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 198000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 199000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 200000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 200001\n","mean reward (100 episodes) 525.400000\n","best mean reward 551.900000\n","running time 1560.629390\n","Train_EnvstepsSoFar : 200001\n","Train_AverageReturn : 525.4\n","Train_BestReturn : 551.9\n","TimeSinceStart : 1560.6293904781342\n","Training Loss : 0.07262928783893585\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 201000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 202000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 203000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 204000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 205000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 206000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 207000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 208000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 209000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 210000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 210001\n","mean reward (100 episodes) 546.200000\n","best mean reward 551.900000\n","running time 1645.272915\n","Train_EnvstepsSoFar : 210001\n","Train_AverageReturn : 546.2\n","Train_BestReturn : 551.9\n","TimeSinceStart : 1645.272914648056\n","Training Loss : 0.11323317140340805\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 211000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 212000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 213000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 214000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 215000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 216000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 217000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 218000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 219000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 220000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 220001\n","mean reward (100 episodes) 541.900000\n","best mean reward 551.900000\n","running time 1730.179113\n","Train_EnvstepsSoFar : 220001\n","Train_AverageReturn : 541.9\n","Train_BestReturn : 551.9\n","TimeSinceStart : 1730.1791133880615\n","Training Loss : 0.09552393853664398\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 221000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 222000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 223000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 224000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 225000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 226000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 227000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 228000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 229000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 230000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 230001\n","mean reward (100 episodes) 576.100000\n","best mean reward 576.100000\n","running time 1814.187101\n","Train_EnvstepsSoFar : 230001\n","Train_AverageReturn : 576.1\n","Train_BestReturn : 576.1\n","TimeSinceStart : 1814.1871011257172\n","Training Loss : 0.26370617747306824\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 231000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 232000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 233000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 234000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 235000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 236000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 237000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 238000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 239000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 240000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 240001\n","mean reward (100 episodes) 642.300000\n","best mean reward 642.300000\n","running time 1898.074337\n","Train_EnvstepsSoFar : 240001\n","Train_AverageReturn : 642.3\n","Train_BestReturn : 642.3\n","TimeSinceStart : 1898.0743370056152\n","Training Loss : 0.08815780282020569\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 241000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 242000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 243000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 244000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 245000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 246000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 247000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 248000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 249000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 250000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 250001\n","mean reward (100 episodes) 633.000000\n","best mean reward 642.300000\n","running time 1982.409334\n","Train_EnvstepsSoFar : 250001\n","Train_AverageReturn : 633.0\n","Train_BestReturn : 642.3\n","TimeSinceStart : 1982.409333705902\n","Training Loss : 0.13938340544700623\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 251000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 252000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 253000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 254000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 255000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 256000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 257000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 258000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 259000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 260000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 260001\n","mean reward (100 episodes) 600.000000\n","best mean reward 642.300000\n","running time 2067.396208\n","Train_EnvstepsSoFar : 260001\n","Train_AverageReturn : 600.0\n","Train_BestReturn : 642.3\n","TimeSinceStart : 2067.3962075710297\n","Training Loss : 0.16907311975955963\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 261000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 262000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 263000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 264000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 265000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 266000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 267000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 268000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 269000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 270000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 270001\n","mean reward (100 episodes) 603.500000\n","best mean reward 642.300000\n","running time 2152.080168\n","Train_EnvstepsSoFar : 270001\n","Train_AverageReturn : 603.5\n","Train_BestReturn : 642.3\n","TimeSinceStart : 2152.080168247223\n","Training Loss : 0.33068451285362244\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 271000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 272000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 273000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 274000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 275000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 276000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 277000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 278000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 279000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 280000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 280001\n","mean reward (100 episodes) 607.800000\n","best mean reward 642.300000\n","running time 2237.512060\n","Train_EnvstepsSoFar : 280001\n","Train_AverageReturn : 607.8\n","Train_BestReturn : 642.3\n","TimeSinceStart : 2237.5120601654053\n","Training Loss : 0.16015276312828064\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 281000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 282000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 283000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 284000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 285000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 286000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 287000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 288000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 289000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 290000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 290001\n","mean reward (100 episodes) 651.100000\n","best mean reward 651.100000\n","running time 2322.657748\n","Train_EnvstepsSoFar : 290001\n","Train_AverageReturn : 651.1\n","Train_BestReturn : 651.1\n","TimeSinceStart : 2322.6577475070953\n","Training Loss : 0.1921752542257309\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 291000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 292000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 293000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 294000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 295000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 296000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 297000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 298000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 299000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 300000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 300001\n","mean reward (100 episodes) 718.900000\n","best mean reward 718.900000\n","running time 2407.447917\n","Train_EnvstepsSoFar : 300001\n","Train_AverageReturn : 718.9\n","Train_BestReturn : 718.9\n","TimeSinceStart : 2407.4479167461395\n","Training Loss : 0.2281520515680313\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 301000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 302000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 303000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 304000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 305000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 306000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 307000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 308000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 309000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 310000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 310001\n","mean reward (100 episodes) 678.600000\n","best mean reward 718.900000\n","running time 2492.783545\n","Train_EnvstepsSoFar : 310001\n","Train_AverageReturn : 678.6\n","Train_BestReturn : 718.9\n","TimeSinceStart : 2492.783544778824\n","Training Loss : 0.29894307255744934\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 311000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 312000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 313000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 314000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 315000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 316000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 317000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 318000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 319000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 320000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 320001\n","mean reward (100 episodes) 662.500000\n","best mean reward 718.900000\n","running time 2579.304879\n","Train_EnvstepsSoFar : 320001\n","Train_AverageReturn : 662.5\n","Train_BestReturn : 718.9\n","TimeSinceStart : 2579.3048791885376\n","Training Loss : 0.11676423251628876\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 321000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 322000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 323000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 324000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 325000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 326000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 327000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 328000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 329000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 330000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 330001\n","mean reward (100 episodes) 746.000000\n","best mean reward 746.000000\n","running time 2665.377177\n","Train_EnvstepsSoFar : 330001\n","Train_AverageReturn : 746.0\n","Train_BestReturn : 746.0\n","TimeSinceStart : 2665.377176761627\n","Training Loss : 0.15976540744304657\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 331000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 332000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 333000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 334000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 335000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 336000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 337000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 338000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 339000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 340000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 340001\n","mean reward (100 episodes) 761.700000\n","best mean reward 761.700000\n","running time 2750.692302\n","Train_EnvstepsSoFar : 340001\n","Train_AverageReturn : 761.7\n","Train_BestReturn : 761.7\n","TimeSinceStart : 2750.692302465439\n","Training Loss : 0.09416373819112778\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 341000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 342000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 343000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 344000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 345000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 346000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 347000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 348000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 349000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 350000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 350001\n","mean reward (100 episodes) 746.200000\n","best mean reward 761.700000\n","running time 2836.367120\n","Train_EnvstepsSoFar : 350001\n","Train_AverageReturn : 746.2\n","Train_BestReturn : 761.7\n","TimeSinceStart : 2836.3671197891235\n","Training Loss : 0.3001593351364136\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 351000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 352000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 353000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 354000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 355000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 356000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 357000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 358000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 359000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 360000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 360001\n","mean reward (100 episodes) 802.700000\n","best mean reward 802.700000\n","running time 2921.923228\n","Train_EnvstepsSoFar : 360001\n","Train_AverageReturn : 802.7\n","Train_BestReturn : 802.7\n","TimeSinceStart : 2921.923228263855\n","Training Loss : 0.5437744855880737\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 361000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 362000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 363000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 364000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 365000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 366000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 367000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 368000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 369000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 370000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 370001\n","mean reward (100 episodes) 782.100000\n","best mean reward 802.700000\n","running time 3006.686742\n","Train_EnvstepsSoFar : 370001\n","Train_AverageReturn : 782.1\n","Train_BestReturn : 802.7\n","TimeSinceStart : 3006.6867418289185\n","Training Loss : 0.1241331696510315\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 371000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 372000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 373000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 374000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 375000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 376000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 377000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 378000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 379000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 380000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 380001\n","mean reward (100 episodes) 761.400000\n","best mean reward 802.700000\n","running time 3092.035734\n","Train_EnvstepsSoFar : 380001\n","Train_AverageReturn : 761.4\n","Train_BestReturn : 802.7\n","TimeSinceStart : 3092.0357336997986\n","Training Loss : 0.2835637927055359\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 381000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 382000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 383000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 384000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 385000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 386000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 387000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 388000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 389000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 390000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 390001\n","mean reward (100 episodes) 818.600000\n","best mean reward 818.600000\n","running time 3177.320174\n","Train_EnvstepsSoFar : 390001\n","Train_AverageReturn : 818.6\n","Train_BestReturn : 818.6\n","TimeSinceStart : 3177.3201735019684\n","Training Loss : 0.37750130891799927\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 391000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 392000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 393000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 394000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 395000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 396000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 397000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 398000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 399000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 400000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 400001\n","mean reward (100 episodes) 863.100000\n","best mean reward 863.100000\n","running time 3262.817626\n","Train_EnvstepsSoFar : 400001\n","Train_AverageReturn : 863.1\n","Train_BestReturn : 863.1\n","TimeSinceStart : 3262.8176255226135\n","Training Loss : 0.13270774483680725\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 401000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 402000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 403000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 404000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 405000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 406000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 407000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 408000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 409000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 410000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 410001\n","mean reward (100 episodes) 802.600000\n","best mean reward 863.100000\n","running time 3348.236155\n","Train_EnvstepsSoFar : 410001\n","Train_AverageReturn : 802.6\n","Train_BestReturn : 863.1\n","TimeSinceStart : 3348.2361550331116\n","Training Loss : 0.3692792057991028\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 411000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 412000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 413000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 414000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 415000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 416000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 417000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 418000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 419000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 420000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 420001\n","mean reward (100 episodes) 796.900000\n","best mean reward 863.100000\n","running time 3433.991658\n","Train_EnvstepsSoFar : 420001\n","Train_AverageReturn : 796.9\n","Train_BestReturn : 863.1\n","TimeSinceStart : 3433.9916577339172\n","Training Loss : 0.31254512071609497\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 421000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 422000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 423000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 424000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 425000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 426000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 427000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 428000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 429000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 430000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 430001\n","mean reward (100 episodes) 851.100000\n","best mean reward 863.100000\n","running time 3519.594272\n","Train_EnvstepsSoFar : 430001\n","Train_AverageReturn : 851.1\n","Train_BestReturn : 863.1\n","TimeSinceStart : 3519.594271659851\n","Training Loss : 0.24688684940338135\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 431000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 432000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 433000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 434000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 435000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 436000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 437000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 438000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 439000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 440000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 440001\n","mean reward (100 episodes) 845.300000\n","best mean reward 863.100000\n","running time 3604.469488\n","Train_EnvstepsSoFar : 440001\n","Train_AverageReturn : 845.3\n","Train_BestReturn : 863.1\n","TimeSinceStart : 3604.4694883823395\n","Training Loss : 0.3354441225528717\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 441000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 442000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 443000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 444000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 445000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 446000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 447000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 448000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 449000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 450000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 450001\n","mean reward (100 episodes) 830.800000\n","best mean reward 863.100000\n","running time 3690.069467\n","Train_EnvstepsSoFar : 450001\n","Train_AverageReturn : 830.8\n","Train_BestReturn : 863.1\n","TimeSinceStart : 3690.0694665908813\n","Training Loss : 0.2518271207809448\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 451000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 452000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 453000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 454000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 455000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 456000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 457000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 458000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 459000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 460000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 460001\n","mean reward (100 episodes) 822.700000\n","best mean reward 863.100000\n","running time 3775.370197\n","Train_EnvstepsSoFar : 460001\n","Train_AverageReturn : 822.7\n","Train_BestReturn : 863.1\n","TimeSinceStart : 3775.3701972961426\n","Training Loss : 0.26028966903686523\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 461000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 462000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 463000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 464000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 465000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 466000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 467000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 468000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 469000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 470000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 470001\n","mean reward (100 episodes) 879.600000\n","best mean reward 879.600000\n","running time 3860.892030\n","Train_EnvstepsSoFar : 470001\n","Train_AverageReturn : 879.6\n","Train_BestReturn : 879.6\n","TimeSinceStart : 3860.8920295238495\n","Training Loss : 0.18437142670154572\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 471000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 472000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 473000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 474000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 475000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 476000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 477000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 478000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 479000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 480000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 480001\n","mean reward (100 episodes) 882.300000\n","best mean reward 882.300000\n","running time 3946.794293\n","Train_EnvstepsSoFar : 480001\n","Train_AverageReturn : 882.3\n","Train_BestReturn : 882.3\n","TimeSinceStart : 3946.794293165207\n","Training Loss : 0.2285587191581726\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 481000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 482000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 483000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 484000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 485000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 486000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 487000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 488000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 489000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 490000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 490001\n","mean reward (100 episodes) 864.000000\n","best mean reward 882.300000\n","running time 4032.711196\n","Train_EnvstepsSoFar : 490001\n","Train_AverageReturn : 864.0\n","Train_BestReturn : 882.3\n","TimeSinceStart : 4032.7111961841583\n","Training Loss : 0.17288431525230408\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 491000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 492000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 493000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 494000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 495000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 496000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 497000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 498000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 499000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 500000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 500001\n","mean reward (100 episodes) 822.600000\n","best mean reward 882.300000\n","running time 4120.122571\n","Train_EnvstepsSoFar : 500001\n","Train_AverageReturn : 822.6\n","Train_BestReturn : 882.3\n","TimeSinceStart : 4120.122571229935\n","Training Loss : 0.37368524074554443\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 501000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 502000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 503000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 504000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 505000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 506000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 507000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 508000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 509000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 510000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 510001\n","mean reward (100 episodes) 818.100000\n","best mean reward 882.300000\n","running time 4205.838885\n","Train_EnvstepsSoFar : 510001\n","Train_AverageReturn : 818.1\n","Train_BestReturn : 882.3\n","TimeSinceStart : 4205.838885068893\n","Training Loss : 0.5607253909111023\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 511000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 512000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 513000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 514000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 515000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 516000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 517000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 518000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 519000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 520000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 520001\n","mean reward (100 episodes) 833.400000\n","best mean reward 882.300000\n","running time 4292.059285\n","Train_EnvstepsSoFar : 520001\n","Train_AverageReturn : 833.4\n","Train_BestReturn : 882.3\n","TimeSinceStart : 4292.059284687042\n","Training Loss : 0.2817951440811157\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 521000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 522000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 523000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 524000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 525000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 526000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 527000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 528000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 529000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 530000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 530001\n","mean reward (100 episodes) 931.700000\n","best mean reward 931.700000\n","running time 4378.006318\n","Train_EnvstepsSoFar : 530001\n","Train_AverageReturn : 931.7\n","Train_BestReturn : 931.7\n","TimeSinceStart : 4378.006318330765\n","Training Loss : 0.21462354063987732\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 531000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 532000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 533000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 534000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 535000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 536000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 537000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 538000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 539000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 540000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 540001\n","mean reward (100 episodes) 955.800000\n","best mean reward 955.800000\n","running time 4464.700976\n","Train_EnvstepsSoFar : 540001\n","Train_AverageReturn : 955.8\n","Train_BestReturn : 955.8\n","TimeSinceStart : 4464.700976133347\n","Training Loss : 0.2536345422267914\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 541000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 542000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 543000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 544000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 545000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 546000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 547000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 548000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 549000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 550000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 550001\n","mean reward (100 episodes) 968.800000\n","best mean reward 968.800000\n","running time 4550.657736\n","Train_EnvstepsSoFar : 550001\n","Train_AverageReturn : 968.8\n","Train_BestReturn : 968.8\n","TimeSinceStart : 4550.657735586166\n","Training Loss : 0.3574269413948059\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 551000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 552000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 553000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 554000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 555000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 556000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 557000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 558000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 559000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 560000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 560001\n","mean reward (100 episodes) 943.900000\n","best mean reward 968.800000\n","running time 4636.661197\n","Train_EnvstepsSoFar : 560001\n","Train_AverageReturn : 943.9\n","Train_BestReturn : 968.8\n","TimeSinceStart : 4636.661197185516\n","Training Loss : 0.27062058448791504\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 561000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 562000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 563000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 564000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 565000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 566000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 567000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 568000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 569000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 570000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 570001\n","mean reward (100 episodes) 958.300000\n","best mean reward 968.800000\n","running time 4723.021514\n","Train_EnvstepsSoFar : 570001\n","Train_AverageReturn : 958.3\n","Train_BestReturn : 968.8\n","TimeSinceStart : 4723.021514415741\n","Training Loss : 0.8146783113479614\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 571000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 572000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 573000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 574000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 575000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 576000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 577000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 578000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 579000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 580000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 580001\n","mean reward (100 episodes) 931.400000\n","best mean reward 968.800000\n","running time 4810.825945\n","Train_EnvstepsSoFar : 580001\n","Train_AverageReturn : 931.4\n","Train_BestReturn : 968.8\n","TimeSinceStart : 4810.825945138931\n","Training Loss : 0.6369360685348511\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 581000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 582000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 583000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 584000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 585000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 586000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 587000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 588000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 589000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 590000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 590001\n","mean reward (100 episodes) 862.100000\n","best mean reward 968.800000\n","running time 4898.094308\n","Train_EnvstepsSoFar : 590001\n","Train_AverageReturn : 862.1\n","Train_BestReturn : 968.8\n","TimeSinceStart : 4898.094308376312\n","Training Loss : 0.4482739567756653\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 591000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 592000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 593000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 594000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 595000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 596000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 597000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 598000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 599000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 600000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 600001\n","mean reward (100 episodes) 871.400000\n","best mean reward 968.800000\n","running time 4984.364833\n","Train_EnvstepsSoFar : 600001\n","Train_AverageReturn : 871.4\n","Train_BestReturn : 968.8\n","TimeSinceStart : 4984.364833116531\n","Training Loss : 0.37509816884994507\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 601000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 602000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 603000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 604000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 605000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 606000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 607000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 608000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 609000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 610000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 610001\n","mean reward (100 episodes) 946.500000\n","best mean reward 968.800000\n","running time 5070.896092\n","Train_EnvstepsSoFar : 610001\n","Train_AverageReturn : 946.5\n","Train_BestReturn : 968.8\n","TimeSinceStart : 5070.896092414856\n","Training Loss : 0.328208327293396\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 611000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 612000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 613000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 614000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 615000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 616000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 617000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 618000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 619000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 620000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 620001\n","mean reward (100 episodes) 1010.900000\n","best mean reward 1010.900000\n","running time 5157.165531\n","Train_EnvstepsSoFar : 620001\n","Train_AverageReturn : 1010.9\n","Train_BestReturn : 1010.9\n","TimeSinceStart : 5157.165531158447\n","Training Loss : 0.16679346561431885\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 621000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 622000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 623000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 624000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 625000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 626000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 627000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 628000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 629000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 630000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 630001\n","mean reward (100 episodes) 1007.300000\n","best mean reward 1010.900000\n","running time 5243.312134\n","Train_EnvstepsSoFar : 630001\n","Train_AverageReturn : 1007.3\n","Train_BestReturn : 1010.9\n","TimeSinceStart : 5243.3121337890625\n","Training Loss : 0.22018833458423615\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 631000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 632000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 633000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 634000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 635000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 636000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 637000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 638000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 639000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 640000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 640001\n","mean reward (100 episodes) 965.500000\n","best mean reward 1010.900000\n","running time 5329.993020\n","Train_EnvstepsSoFar : 640001\n","Train_AverageReturn : 965.5\n","Train_BestReturn : 1010.9\n","TimeSinceStart : 5329.993019580841\n","Training Loss : 0.48530906438827515\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 641000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 642000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 643000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 644000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 645000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 646000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 647000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 648000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 649000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 650000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 650001\n","mean reward (100 episodes) 1013.800000\n","best mean reward 1013.800000\n","running time 5416.630229\n","Train_EnvstepsSoFar : 650001\n","Train_AverageReturn : 1013.8\n","Train_BestReturn : 1013.8\n","TimeSinceStart : 5416.630229473114\n","Training Loss : 0.3149653673171997\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 651000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 652000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 653000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 654000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 655000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 656000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 657000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 658000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 659000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 660000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 660001\n","mean reward (100 episodes) 1105.500000\n","best mean reward 1105.500000\n","running time 5503.611431\n","Train_EnvstepsSoFar : 660001\n","Train_AverageReturn : 1105.5\n","Train_BestReturn : 1105.5\n","TimeSinceStart : 5503.611431360245\n","Training Loss : 0.4338339865207672\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 661000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 662000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 663000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 664000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 665000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 666000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 667000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 668000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 669000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 670000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 670001\n","mean reward (100 episodes) 1172.400000\n","best mean reward 1172.400000\n","running time 5590.612910\n","Train_EnvstepsSoFar : 670001\n","Train_AverageReturn : 1172.4\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 5590.612910270691\n","Training Loss : 0.27184534072875977\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 671000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 672000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 673000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 674000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 675000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 676000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 677000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 678000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 679000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 680000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 680001\n","mean reward (100 episodes) 1120.200000\n","best mean reward 1172.400000\n","running time 5677.296219\n","Train_EnvstepsSoFar : 680001\n","Train_AverageReturn : 1120.2\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 5677.2962193489075\n","Training Loss : 0.5371707081794739\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 681000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 682000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 683000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 684000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 685000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 686000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 687000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 688000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 689000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 690000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 690001\n","mean reward (100 episodes) 1098.700000\n","best mean reward 1172.400000\n","running time 5764.325212\n","Train_EnvstepsSoFar : 690001\n","Train_AverageReturn : 1098.7\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 5764.3252120018005\n","Training Loss : 0.4017179608345032\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 691000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 692000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 693000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 694000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 695000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 696000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 697000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 698000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 699000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 700000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 700001\n","mean reward (100 episodes) 1078.000000\n","best mean reward 1172.400000\n","running time 5850.760161\n","Train_EnvstepsSoFar : 700001\n","Train_AverageReturn : 1078.0\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 5850.760160684586\n","Training Loss : 0.5190659761428833\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 701000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 702000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 703000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 704000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 705000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 706000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 707000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 708000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 709000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 710000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 710001\n","mean reward (100 episodes) 1072.100000\n","best mean reward 1172.400000\n","running time 5937.706697\n","Train_EnvstepsSoFar : 710001\n","Train_AverageReturn : 1072.1\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 5937.706696510315\n","Training Loss : 0.40180766582489014\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 711000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 712000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 713000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 714000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 715000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 716000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 717000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 718000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 719000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 720000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 720001\n","mean reward (100 episodes) 1071.700000\n","best mean reward 1172.400000\n","running time 6024.562433\n","Train_EnvstepsSoFar : 720001\n","Train_AverageReturn : 1071.7\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 6024.562432765961\n","Training Loss : 0.4296594560146332\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 721000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 722000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 723000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 724000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 725000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 726000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 727000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 728000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 729000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 730000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 730001\n","mean reward (100 episodes) 1091.000000\n","best mean reward 1172.400000\n","running time 6111.267474\n","Train_EnvstepsSoFar : 730001\n","Train_AverageReturn : 1091.0\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 6111.267474412918\n","Training Loss : 0.45480114221572876\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 731000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 732000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 733000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 734000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 735000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 736000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 737000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 738000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 739000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 740000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 740001\n","mean reward (100 episodes) 1165.200000\n","best mean reward 1172.400000\n","running time 6198.213051\n","Train_EnvstepsSoFar : 740001\n","Train_AverageReturn : 1165.2\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 6198.213051319122\n","Training Loss : 0.3326795697212219\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 741000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 742000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 743000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 744000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 745000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 746000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 747000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 748000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 749000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 750000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 750001\n","mean reward (100 episodes) 1150.300000\n","best mean reward 1172.400000\n","running time 6285.079208\n","Train_EnvstepsSoFar : 750001\n","Train_AverageReturn : 1150.3\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 6285.079207658768\n","Training Loss : 0.3973083794116974\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 751000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 752000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 753000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 754000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 755000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 756000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 757000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 758000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 759000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 760000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 760001\n","mean reward (100 episodes) 1114.100000\n","best mean reward 1172.400000\n","running time 6371.998737\n","Train_EnvstepsSoFar : 760001\n","Train_AverageReturn : 1114.1\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 6371.9987370967865\n","Training Loss : 0.3279055058956146\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 761000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 762000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 763000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 764000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 765000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 766000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 767000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 768000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 769000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 770000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 770001\n","mean reward (100 episodes) 1132.400000\n","best mean reward 1172.400000\n","running time 6459.156574\n","Train_EnvstepsSoFar : 770001\n","Train_AverageReturn : 1132.4\n","Train_BestReturn : 1172.4\n","TimeSinceStart : 6459.156573534012\n","Training Loss : 0.33663707971572876\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 771000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 772000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 773000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 774000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 775000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 776000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 777000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 778000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 779000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 780000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 780001\n","mean reward (100 episodes) 1246.100000\n","best mean reward 1246.100000\n","running time 6546.358404\n","Train_EnvstepsSoFar : 780001\n","Train_AverageReturn : 1246.1\n","Train_BestReturn : 1246.1\n","TimeSinceStart : 6546.3584043979645\n","Training Loss : 0.47760528326034546\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 781000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 782000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 783000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 784000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 785000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 786000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 787000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 788000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 789000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 790000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 790001\n","mean reward (100 episodes) 1264.400000\n","best mean reward 1264.400000\n","running time 6633.283197\n","Train_EnvstepsSoFar : 790001\n","Train_AverageReturn : 1264.4\n","Train_BestReturn : 1264.4\n","TimeSinceStart : 6633.283197402954\n","Training Loss : 0.2139001190662384\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 791000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 792000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 793000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 794000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 795000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 796000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 797000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 798000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 799000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 800000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 800001\n","mean reward (100 episodes) 1266.300000\n","best mean reward 1266.300000\n","running time 6719.407350\n","Train_EnvstepsSoFar : 800001\n","Train_AverageReturn : 1266.3\n","Train_BestReturn : 1266.3\n","TimeSinceStart : 6719.407349824905\n","Training Loss : 0.4440796971321106\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 801000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 802000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 803000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 804000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 805000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 806000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 807000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 808000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 809000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 810000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 810001\n","mean reward (100 episodes) 1286.800000\n","best mean reward 1286.800000\n","running time 6806.248137\n","Train_EnvstepsSoFar : 810001\n","Train_AverageReturn : 1286.8\n","Train_BestReturn : 1286.8\n","TimeSinceStart : 6806.248136520386\n","Training Loss : 0.5329132080078125\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 811000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 812000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 813000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 814000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 815000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 816000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 817000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 818000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 819000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 820000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 820001\n","mean reward (100 episodes) 1334.300000\n","best mean reward 1334.300000\n","running time 6892.835398\n","Train_EnvstepsSoFar : 820001\n","Train_AverageReturn : 1334.3\n","Train_BestReturn : 1334.3\n","TimeSinceStart : 6892.835398435593\n","Training Loss : 0.264046847820282\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 821000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 822000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 823000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 824000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 825000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 826000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 827000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 828000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 829000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 830000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 830001\n","mean reward (100 episodes) 1343.400000\n","best mean reward 1343.400000\n","running time 6979.002079\n","Train_EnvstepsSoFar : 830001\n","Train_AverageReturn : 1343.4\n","Train_BestReturn : 1343.4\n","TimeSinceStart : 6979.002078771591\n","Training Loss : 0.7461591958999634\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 831000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 832000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 833000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 834000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 835000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 836000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 837000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 838000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 839000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 840000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 840001\n","mean reward (100 episodes) 1446.900000\n","best mean reward 1446.900000\n","running time 7065.573532\n","Train_EnvstepsSoFar : 840001\n","Train_AverageReturn : 1446.9\n","Train_BestReturn : 1446.9\n","TimeSinceStart : 7065.573532342911\n","Training Loss : 0.6342878341674805\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 841000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 842000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 843000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 844000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 845000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 846000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 847000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 848000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 849000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 850000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 850001\n","mean reward (100 episodes) 1442.600000\n","best mean reward 1446.900000\n","running time 7152.720800\n","Train_EnvstepsSoFar : 850001\n","Train_AverageReturn : 1442.6\n","Train_BestReturn : 1446.9\n","TimeSinceStart : 7152.720800161362\n","Training Loss : 0.7651382684707642\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 851000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 852000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 853000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 854000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 855000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 856000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 857000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 858000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 859000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 860000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 860001\n","mean reward (100 episodes) 1414.000000\n","best mean reward 1446.900000\n","running time 7239.003188\n","Train_EnvstepsSoFar : 860001\n","Train_AverageReturn : 1414.0\n","Train_BestReturn : 1446.9\n","TimeSinceStart : 7239.00318813324\n","Training Loss : 0.5726703405380249\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 861000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 862000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 863000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 864000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 865000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 866000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 867000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 868000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 869000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 870000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 870001\n","mean reward (100 episodes) 1400.200000\n","best mean reward 1446.900000\n","running time 7325.145149\n","Train_EnvstepsSoFar : 870001\n","Train_AverageReturn : 1400.2\n","Train_BestReturn : 1446.9\n","TimeSinceStart : 7325.145148515701\n","Training Loss : 0.5104970335960388\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 871000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 872000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 873000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 874000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 875000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 876000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 877000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 878000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 879000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 880000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 880001\n","mean reward (100 episodes) 1534.100000\n","best mean reward 1534.100000\n","running time 7411.524822\n","Train_EnvstepsSoFar : 880001\n","Train_AverageReturn : 1534.1\n","Train_BestReturn : 1534.1\n","TimeSinceStart : 7411.524822473526\n","Training Loss : 0.6244497895240784\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 881000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 882000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 883000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 884000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 885000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 886000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 887000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 888000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 889000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 890000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 890001\n","mean reward (100 episodes) 1541.300000\n","best mean reward 1541.300000\n","running time 7497.886011\n","Train_EnvstepsSoFar : 890001\n","Train_AverageReturn : 1541.3\n","Train_BestReturn : 1541.3\n","TimeSinceStart : 7497.886010885239\n","Training Loss : 0.6295387744903564\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 891000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 892000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 893000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 894000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 895000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 896000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 897000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 898000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 899000 ************\n","\n","Training agent...\n"]}]},{"cell_type":"code","metadata":{"id":"_kTH-tXkI-B-"},"source":["#@markdown You can visualize your runs with tensorboard from within the notebook\n","\n","## requires tensorflow==2.3.0\n","%load_ext tensorboard\n","%tensorboard --logdir /content/hw_16831/hw_16831/data"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CRv5ZFRvxrln"},"execution_count":null,"outputs":[]}]}